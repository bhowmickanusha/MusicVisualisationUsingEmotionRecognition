# MusicVisualisationUsingEmotionRecognition
Currently, this is for Hindustani Classical Music. Aims to apply ML to classify a classical music audio clip into an emotion class, and use this emotion class to visually represent the audio temporally. Future work will look towards applying the same methodology for better visual representation and expansion for all genres of music.


Read the Powerpoint Presentation for the approach, flowcharts and screenshots.
If you want to run the code, download all the files here to your local computer. Run frontpage.html on Chrome to choose a songfile out of a few (I am terrible at building websites/frontend, sorryyyy). Run predictmodel1.py and predictmodel2.py if you just want to predict the valence and arousal classes for a songfile. Run the main FAudioWaveform.pde file to see the visualiation for the chosen songfile.

Make sure you have Java, Processing and Python installed on your computer.
If you want to manually extract features from Hindustani classical song files, install Matlab and mirtoolbox, and run the code given in featureextraction_featuresetformodel1.txt on Matlab (this is not the complete code. matlab code for model2 will be uploaded soon.)

Feel free to contact me at anushabhowmick@ymail.com for more details on the implementation (and if you find anything missing, sorry :p)

I basically reverse engineered this. Decide what I wanted to build and then learnt about Machine Learning :] So I know there must be many mistakes and this is not the most optimal solution, but I got what I wanted to create at the end. I'd love to have more guidance, and build more on themes like this (music + tech + visual art + immersive experience based on emotions)...perhaps you'll see more repositories here on the same in the future.
